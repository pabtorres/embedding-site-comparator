{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNoiPosfRl1X"
      },
      "outputs": [],
      "source": [
        "!pip install playwright transformers sentence-transformers beautifulsoup4 lxml\n",
        "!playwright install-deps\n",
        "!playwright install\n",
        "\n",
        "import torch\n",
        "import requests\n",
        "from bs4 import BeautifulSoup, Comment\n",
        "from playwright.async_api import async_playwright\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from PIL import Image\n",
        "\n",
        "# =========================\n",
        "#   1) CAPTURAR PANTALLA\n",
        "# =========================\n",
        "\n",
        "async def capture_screenshot(url, path):\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(headless=True)\n",
        "        page = await browser.new_page(viewport={\"width\":1280, \"height\":800})\n",
        "        await page.goto(url, wait_until=\"networkidle\", timeout=30000)\n",
        "        await page.screenshot(path=path, full_page=True)\n",
        "        await browser.close()\n",
        "\n",
        "# =========================\n",
        "#   2) EMBEDDING VISUAL CLIP\n",
        "# =========================\n",
        "\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "_clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "_clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "def embed_image_clip(path):\n",
        "    image = Image.open(path).convert(\"RGB\")\n",
        "    inputs = _clip_processor(images=image, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = _clip_model.get_image_features(**inputs)\n",
        "    return outputs.squeeze()\n",
        "\n",
        "# =========================\n",
        "#   3) EMBEDDING DE TEXTO\n",
        "# =========================\n",
        "\n",
        "_text_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def extract_visible_text(html):\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "    for script in soup([\"script\", \"style\"]):\n",
        "        script.extract()\n",
        "    texts = soup.stripped_strings\n",
        "    return \" \".join(texts)\n",
        "\n",
        "def embed_text_sentence_transformer(text):\n",
        "    emb = _text_model.encode(text, convert_to_tensor=True)\n",
        "    return emb\n",
        "\n",
        "# ======================================================\n",
        "#   4) EMBEDDING ESTRUCTURAL HTML - MarkupLM SIMPLIFICADO\n",
        "# ======================================================\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/markuplm-base\")\n",
        "markuplm = AutoModel.from_pretrained(\"microsoft/markuplm-base\")\n",
        "\n",
        "def extract_nodes(html):\n",
        "    \"\"\"\n",
        "    Extrae nodos simples (solo tags) sin XPath real.\n",
        "    MarkupLM funcionar√° pero en modo degradado.\n",
        "    \"\"\"\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "    nodes = [tag.name for tag in soup.find_all()]\n",
        "    xpaths = [\"x\"] * len(nodes)  # placeholder requerido por MarkupLM\n",
        "    return nodes, xpaths\n",
        "\n",
        "def embed_html_markuplm_from_url(url):\n",
        "    html = requests.get(url, timeout=10).text\n",
        "    nodes, xpaths = extract_nodes(html)\n",
        "\n",
        "    if len(nodes) == 0:\n",
        "        return torch.zeros(768)\n",
        "\n",
        "    # MarkupLM espera listas de listas\n",
        "    inputs = tokenizer(\n",
        "        [nodes],\n",
        "        xpaths=[xpaths],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = markuplm(**inputs).last_hidden_state.mean(dim=1).squeeze()\n",
        "\n",
        "    return out\n",
        "\n",
        "# =========================\n",
        "#   5) FUSI√ìN H√çBRIDA\n",
        "# =========================\n",
        "\n",
        "def embed_site_from_screenshot(url, screenshot_path):\n",
        "    print(f\"Procesando {url}\")\n",
        "\n",
        "    # Visual\n",
        "    emb_img = embed_image_clip(screenshot_path)\n",
        "\n",
        "    # Texto\n",
        "    html = requests.get(url, timeout=10).text\n",
        "    text = extract_visible_text(html)\n",
        "    emb_text = embed_text_sentence_transformer(text)\n",
        "\n",
        "    # HTML estructural\n",
        "    emb_html = embed_html_markuplm_from_url(url)\n",
        "\n",
        "    # Fusionar (normalizado)\n",
        "    emb_img = emb_img / emb_img.norm()\n",
        "    emb_text = emb_text / emb_text.norm()\n",
        "    emb_html = emb_html / emb_html.norm()\n",
        "\n",
        "    fused = torch.cat([\n",
        "        0.6 * emb_img,\n",
        "        0.3 * emb_text,\n",
        "        0.1 * emb_html\n",
        "    ], dim=0)\n",
        "\n",
        "    fused = fused / fused.norm()\n",
        "    return fused, emb_img, emb_text, emb_html\n",
        "\n",
        "# =========================\n",
        "#   6) DEMO COMPLETA\n",
        "# =========================\n",
        "\n",
        "# capturar pantallas\n",
        "await capture_screenshot(\"https://users.dcc.uchile.cl/~patorres/\", \"p1.png\")\n",
        "await capture_screenshot(\"http://example.com\", \"p2.png\")\n",
        "\n",
        "# embeddings\n",
        "emb1, emb_img_1, emb_text_1, emb_html_1 = embed_site_from_screenshot(\"https://users.dcc.uchile.cl/~patorres/\", \"p1.png\")\n",
        "emb2, emb_img_2, emb_text_2, emb_html_2 = embed_site_from_screenshot(\"http://example.com\", \"p2.png\")\n",
        "\n",
        "# similitud\n",
        "sim = torch.nn.functional.cosine_similarity(emb1.unsqueeze(0), emb2.unsqueeze(0)).item()\n",
        "print(\"Similitud h√≠brida final:\", sim)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(x):\n",
        "    return x / (x.norm() + 1e-12)\n",
        "\n",
        "def similarity(a, b):\n",
        "    return torch.nn.functional.cosine_similarity(\n",
        "        a.unsqueeze(0), b.unsqueeze(0)\n",
        "    ).item()\n",
        "\n",
        "def explain_similarity(embA, embB):\n",
        "    \"\"\"\n",
        "    embA y embB deben ser diccionarios:\n",
        "    {\n",
        "        \"hyb\": tensor,\n",
        "        \"img\": tensor,\n",
        "        \"text\": tensor,\n",
        "        \"html\": tensor\n",
        "    }\n",
        "    \"\"\"\n",
        "    # Normalizar\n",
        "    vA = normalize(embA[\"img\"])\n",
        "    tA = normalize(embA[\"text\"])\n",
        "    hA = normalize(embA[\"html\"])\n",
        "\n",
        "    vB = normalize(embB[\"img\"])\n",
        "    tB = normalize(embB[\"text\"])\n",
        "    hB = normalize(embB[\"html\"])\n",
        "\n",
        "    # Similitudes individuales\n",
        "    sim_v = similarity(vA, vB)\n",
        "    sim_t = similarity(tA, tB)\n",
        "    sim_h = similarity(hA, hB)\n",
        "\n",
        "    sim_final = similarity(embA[\"hyb\"], embB[\"hyb\"])\n",
        "\n",
        "    # Reporte\n",
        "    return {\n",
        "        \"sim_visual\": sim_v,\n",
        "        \"sim_textual\": sim_t,\n",
        "        \"sim_html\": sim_h,\n",
        "        \"sim_global\": sim_final\n",
        "    }\n"
      ],
      "metadata": {
        "id": "AHzj4D70RmyA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_site1 = {\n",
        "    \"hyb\": emb1,\n",
        "    \"img\": emb_img_1,\n",
        "    \"text\": emb_text_1,\n",
        "    \"html\": emb_html_1\n",
        "}\n",
        "\n",
        "emb_site2 = {\n",
        "    \"hyb\": emb2,\n",
        "    \"img\": emb_img_2,\n",
        "    \"text\": emb_text_2,\n",
        "    \"html\": emb_html_2\n",
        "}\n",
        "\n",
        "report = explain_similarity(emb_site1, emb_site2)\n",
        "report\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-6bCsRhRqBx",
        "outputId": "0b72aeee-e552-46df-9f23-2d3371f52c50"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sim_visual': 0.3249787390232086,\n",
              " 'sim_textual': 0.01665947586297989,\n",
              " 'sim_html': 0.9309614896774292,\n",
              " 'sim_global': 0.27782896161079407}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# capturar pantallas\n",
        "await capture_screenshot(\"https://users.dcc.uchile.cl/~patorres/\", \"p1.png\")\n",
        "await capture_screenshot(\"http://example.com\", \"p2.png\")\n",
        "\n",
        "# embeddings\n",
        "emb1, emb_img_1, emb_text_1, emb_html_1 = embed_site_from_screenshot(\"https://users.dcc.uchile.cl/~patorres/\", \"p1.png\")\n",
        "emb2, emb_img_2, emb_text_2, emb_html_2 = embed_site_from_screenshot(\"http://example.com\", \"p2.png\")\n",
        "\n",
        "# similitud\n",
        "sim = torch.nn.functional.cosine_similarity(emb1.unsqueeze(0), emb2.unsqueeze(0)).item()\n",
        "print(\"Similitud h√≠brida final:\", sim)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX3GjsA4XrAv",
        "outputId": "2ac0a8f1-d5a6-46c1-9cec-6c054fdd8c7a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando https://users.dcc.uchile.cl/~patorres/\n",
            "Procesando http://example.com\n",
            "Similitud h√≠brida final: 0.27898624539375305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets --quiet\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import torch\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# CAPA EMBEDDINGS\n",
        "# -----------------------------------------------------------\n",
        "async def gen_embed(url):\n",
        "  await capture_screenshot(url, f'{url}.png')\n",
        "  return embed_site_from_screenshot(url, f'{url}.png')\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# WIDGETS\n",
        "# -----------------------------------------------------------\n",
        "url1_box = widgets.Text(\n",
        "    value=\"https://example.com\",\n",
        "    placeholder=\"https://...\",\n",
        "    description=\"Sitio A:\",\n",
        "    layout=widgets.Layout(width='600px')\n",
        ")\n",
        "\n",
        "url2_box = widgets.Text(\n",
        "    value=\"https://wikipedia.org\",\n",
        "    placeholder=\"https://...\",\n",
        "    description=\"Sitio B:\",\n",
        "    layout=widgets.Layout(width='600px')\n",
        ")\n",
        "\n",
        "btn_compare = widgets.Button(\n",
        "    description=\"Comparar\",\n",
        "    button_style=\"primary\"\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# L√ìGICA DEL BOT√ìN\n",
        "# -----------------------------------------------------------\n",
        "def on_compare_clicked(b):\n",
        "    output.clear_output()\n",
        "\n",
        "    url1 = url1_box.value\n",
        "    url2 = url2_box.value\n",
        "\n",
        "    with output:\n",
        "        print(\"Procesando...\\n\")\n",
        "\n",
        "        emb1 = gen_embed(url1)\n",
        "        emb2 = gen_embed(url2)\n",
        "\n",
        "        print(\"üîç Resultados de similitud:\\n\")\n",
        "\n",
        "        report = explain_similarity(emb_site1, emb_site2)\n",
        "\n",
        "        print(\"SIM Visual:     \", round(report['sim_visual'],2))\n",
        "        print(\"SIM Textual:  \", round(report['sim_textual'],2))\n",
        "        print(\"SIM HTML:  \", round(report['sim_html'],2))\n",
        "        print(\"SIM Total:   \", round(report['sim_global'],2))\n",
        "\n",
        "btn_compare.on_click(on_compare_clicked)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# MOSTRAR UI\n",
        "# -----------------------------------------------------------\n",
        "display(url1_box, url2_box, btn_compare, output)\n"
      ],
      "metadata": {
        "id": "lbSy6PREWbf3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}